---
layout: post
title: "Linux GPU, CUDA setup"
date: 2025-10-20 00:33:00 +0000
categories: [IT]
tags: [linux, cuda, gpu, pytorch]
author: "JayLL"
---

All notes here were taken in a Windows PC environment (WSL), utilizing an RTX 5090 GPU and CUDA 12.8 - CUDA 13. 

## Install on WSL

###[Download Cuda Toolkit](https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=WSL-Ubuntu&target_version=2.0&target_type=deb_network)

You may get commands for installation on Linux, or executable file on Windows.

### [Cuda Toolkit Installation](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#with-apt-ubuntu-debian)

Quick commands:

```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
# sudo apt-get -y install cuda-toolkit-13-0
sudo apt-get -y install cuda-toolkit-12-8
```

## Pytorch NVIDIA Docker image for developing:

[Pytorch NVIDIA Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch)

Run with Docker:

```bash
docker run --gpus all -it --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 nvcr.io/nvidia/pytorch:25.09-py3
```

## Run GPU benchmark

Here are some commands/scripts for testing whether Pytorch can run with GPU/CUDA successfully.

### Testing in Docker environment:

```bash
docker run -it --gpus=all --rm nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -benchmark
```

## Python script for testing Pytorch - GPU

```python
import torch
torch.cuda.is_available()
torch.cuda.device_count()
torch.cuda.current_device()
torch.cuda.device(0)
torch.cuda.get_device_name(0)
```

or you may use bash command instead of using python scrips:

```bash
python --version
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"
python -c "import torch; print(torch.cuda.get_device_name(0))"
python -c "import torch; print(torch.version.cuda)"
```
